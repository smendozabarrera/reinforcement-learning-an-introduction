* Reinforcement Learning: An Introduction
  :PROPERTIES:
  :CUSTOM_ID: reinforcement-learning-an-introduction
  :END:

[[https://travis-ci.org/ShangtongZhang/reinforcement-learning-an-introduction][[[https://travis-ci.org/ShangtongZhang/reinforcement-learning-an-introduction.svg?branch=master]]]]

Python code for Sutton & Barto's book
[[http://incompleteideas.net/book/the-book-2nd.html][/Reinforcement
Learning: An Introduction (2nd Edition)/]]

#+BEGIN_QUOTE
  If you have any confusion about the code or want to report a bug,
  please open an issue instead of emailing me directly.
#+END_QUOTE

* Contents
  :PROPERTIES:
  :CUSTOM_ID: contents
  :END:

*** Chapter 1
    :PROPERTIES:
    :CUSTOM_ID: chapter-1
    :END:

1. Tic-Tac-Toe

*** Chapter 2
    :PROPERTIES:
    :CUSTOM_ID: chapter-2
    :END:

1. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_2_1.png][Figure 2.1: An exemplary bandit problem from the 10-armed testbed]]
2. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_2_2.png][Figure 2.2: Average performance of epsilon-greedy action-value methods on the 10-armed testbed]]
3. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_2_3.png][Figure 2.3: Optimistic initial action-value estimates]]
4. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_2_4.png][Figure 2.4: Average performance of UCB action selection on the 10-armed testbed]]
5. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_2_5.png][Figure 2.5: Average performance of the gradient bandit algorithm]]
6. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_2_6.png][Figure 2.6: A parameter study of the various bandit algorithms]]

*** Chapter 3
    :PROPERTIES:
    :CUSTOM_ID: chapter-3
    :END:

1. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_3_2.png][Figure 3.2: Grid example with random policy]]
2. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_3_5.png][Figure 3.5: Optimal solutions to the gridworld example]]

*** Chapter 4
    :PROPERTIES:
    :CUSTOM_ID: chapter-4
    :END:

1. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_4_1.png][Figure 4.1: Convergence of iterative policy evaluation on a small gridworld]]
2. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_4_2.png][Figure 4.2: Jack's car rental problem]]
3. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_4_3.png][Figure 4.3: The solution to the gambler's problem]]

*** Chapter 5
    :PROPERTIES:
    :CUSTOM_ID: chapter-5
    :END:

1. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_5_1.png][Figure 5.1: Approximate state-value functions for the blackjack policy]]
2. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_5_2.png][Figure 5.2: The optimal policy and state-value function for blackjack found by Monte Carlo ES]]
3. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_5_3.png][Figure 5.3: Weighted importance sampling]]
4. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_5_4.png][Figure 5.4: Ordinary importance sampling with surprisingly unstable estimates]]

*** Chapter 6
    :PROPERTIES:
    :CUSTOM_ID: chapter-6
    :END:

1. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/example_6_2.png][Example 6.2: Random walk]]
2. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_6_2.png][Figure 6.2: Batch updating]]
3. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_6_3.png][Figure 6.3: Sarsa applied to windy grid world]]
4. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_6_4.png][Figure 6.4: The cliff-walking task]]
5. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_6_6.png][Figure 6.6: Interim and asymptotic performance of TD control methods]]
6. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_6_7.png][Figure 6.7: Comparison of Q-learning and Double Q-learning]]

*** Chapter 7
    :PROPERTIES:
    :CUSTOM_ID: chapter-7
    :END:

1. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_7_2.png][Figure 7.2: Performance of n-step TD methods on 19-state random walk]]

*** Chapter 8
    :PROPERTIES:
    :CUSTOM_ID: chapter-8
    :END:

1. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_8_2.png][Figure 8.2: Average learning curves for Dyna-Q agents varying in their number of planning steps]]
2. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_8_4.png][Figure 8.4: Average performance of Dyna agents on a blocking task]]
3. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_8_5.png][Figure 8.5: Average performance of Dyna agents on a shortcut task]]
4. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/example_8_4.png][Example 8.4: Prioritized sweeping significantly shortens learning time on the Dyna maze task]]
5. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_8_7.png][Figure 8.7: Comparison of efficiency of expected and sample updates]]
6. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_8_8.png][Figure 8.8: Relative efficiency of different update distributions]]

*** Chapter 9
    :PROPERTIES:
    :CUSTOM_ID: chapter-9
    :END:

1. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_9_1.png][Figure 9.1: Gradient Monte Carlo algorithm on the 1000-state random walk task]]
2. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_9_2.png][Figure 9.2: Semi-gradient n-steps TD algorithm on the 1000-state random walk task]]
3. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_9_5.png][Figure 9.5: Fourier basis vs polynomials on the 1000-state random walk task]]
4. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_9_8.png][Figure 9.8: Example of feature width's effect on initial generalization and asymptotic accuracy]]
5. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_9_10.png][Figure 9.10: Single tiling and multiple tilings on the 1000-state random walk task]]

*** Chapter 10
    :PROPERTIES:
    :CUSTOM_ID: chapter-10
    :END:

1. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_10_1.png][Figure 10.1: The cost-to-go function for Mountain Car task in one run]]
2. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_10_2.png][Figure 10.2: Learning curves for semi-gradient Sarsa on Mountain Car task]]
3. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_10_3.png][Figure 10.3: One-step vs multi-step performance of semi-gradient Sarsa on the Mountain Car task]]
4. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_10_4.png][Figure 10.4: Effect of the alpha and n on early performance of n-step semi-gradient Sarsa]]
5. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_10_5.png][Figure 10.5: Differential semi-gradient Sarsa on the access-control queuing task]]

*** Chapter 11
    :PROPERTIES:
    :CUSTOM_ID: chapter-11
    :END:

1. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_11_2.png][Figure 11.2: Baird's Counterexample]]
2. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_11_6.png][Figure 11.6: The behavior of the TDC algorithm on Baird's counterexample]]
3. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_11_7.png][Figure 11.7: The behavior of the ETD algorithm in expectation on Baird's counterexample]]

*** Chapter 12
    :PROPERTIES:
    :CUSTOM_ID: chapter-12
    :END:

1. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_12_3.png][Figure 12.3: Off-line λ-return algorithm on 19-state random walk]]
2. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_12_6.png][Figure 12.6: TD(λ) algorithm on 19-state random walk]]
3. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_12_8.png][Figure 12.8: True online TD(λ) algorithm on 19-state random walk]]
4. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_12_10.png][Figure 12.10: Sarsa(λ) with replacing traces on Mountain Car]]
5. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_12_11.png][Figure 12.11: Summary comparison of Sarsa(λ) algorithms on Mountain Car]]

*** Chapter 13
    :PROPERTIES:
    :CUSTOM_ID: chapter-13
    :END:

1. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/example_13_1.png][Example 13.1: Short corridor with switched actions]]
2. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_13_1.png][Figure13.1: REINFORCE on the short-corridor grid world]]
3. [[https://raw.githubusercontent.com/ShangtongZhang/reinforcement-learning-an-introduction/master/images/figure_13_2.png][Figure 13.2: REINFORCE with baseline on the short-corridor grid-world]]

* Environment
  :PROPERTIES:
  :CUSTOM_ID: environment
  :END:

- python 3.6
- numpy
- matplotlib
- [[https://seaborn.pydata.org/index.html][seaborn]]
- [[https://pypi.org/project/tqdm/][tqdm]]

* Usage
  :PROPERTIES:
  :CUSTOM_ID: usage
  :END:

#+BEGIN_QUOTE
  All files are self-contained
#+END_QUOTE

#+BEGIN_EXAMPLE
    python any_file_you_want.py
#+END_EXAMPLE

* Contribution
  :PROPERTIES:
  :CUSTOM_ID: contribution
  :END:

If you want to contribute some missing examples or fix some bugs, feel
free to open an issue or make a pull request.

Following are missing figures/examples:

- Figure 12.14: The effect of λ

* Resources

- http://incompleteideas.net/book/the-book.html
- http://incompleteideas.net/609%20dropbox/

** Project tree

#+begin_src R :results output :exports all
  Install_And_Load <- function(Required_Packages)
  {
          Remaining_Packages <- Required_Packages[!(Required_Packages %in%
                                                    installed.packages()[,"Package"])];

          if(length(Remaining_Packages))
          {
                  install.packages(Remaining_Packages, repos='http://cran.rstudio.com/');
          }
          for(package_name in Required_Packages)
          {
                  library(package_name,character.only=TRUE,quietly=TRUE);
          }
  }

  ## Specify the list of required packages to be installed and load
  Required_Packages <- "ProjectTemplate"
  ## Call the Function
  Install_And_Load(Required_Packages);

  ## Name your project
  create.project('RL')
#+end_src

#+RESULTS:
